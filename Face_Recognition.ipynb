{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOozxY8yHG4QqcV1bLE8gyr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sherifmost/face-recognition/blob/main/Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlMQSGkWuRhC"
      },
      "source": [
        "### **About the project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlWcBMiNuYn4"
      },
      "source": [
        "This is a project in the information systems and software course. Our objective is to perform face recognition on the ORL dataset and test its accuracy using PCA and LDA along with KNN classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoWtEudgurgr"
      },
      "source": [
        "### **About the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii2iyB4Hutuu"
      },
      "source": [
        "We used the ORL data set for face recognition, which contains 40 different subjects with 10 images each. Each image is a 92x112 image in PGM (Portable Gray Map) format. Images are classified by being placed in different directories; where those in folder sx belong to subject number x(x between 1 and 40). An image for a certain subject is named Y.pmg where Y is the image number (between 1 and 10).\n",
        "Credits to: *AT&T Laboratories Cambridge* for providing the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HlnhRnDvc97"
      },
      "source": [
        "### **Needed library imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-5KLVtTvxz3"
      },
      "source": [
        "from google.colab import drive\n",
        "# used to manipulate the folders containing the images and read them out\n",
        "import os\n",
        "import matplotlib.image as mpimg \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5BOIf4Gvy1O"
      },
      "source": [
        "### **Labels and constants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9mMSXtkv5Q8"
      },
      "source": [
        "# file paths\n",
        "path_data = '/content/drive/My Drive/Information systems/Assignment 1/Data set';\n",
        "\n",
        "# symbols\n",
        "delim = '/';\n",
        "\n",
        "# image dimensions\n",
        "image_len = 92;\n",
        "image_width = 112;\n",
        "\n",
        "# constant numbers\n",
        "training = 1;\n",
        "testing = -1;"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcphDZSL6gOh"
      },
      "source": [
        "### **Helper functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK0_u8y757BS"
      },
      "source": [
        "# functions used as keys for sort function\n",
        "def numeric_key_folders(x):\n",
        "  return int(x[1:]);\n",
        "def numeric_key_images(x):\n",
        "  # we want to get the number till .pmg so remove last 4 characters from the string considered\n",
        "  return int(x[0:(len(x)-4)]);"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctPEnjwTv6Fh"
      },
      "source": [
        "### **Obtaining the data and cleaning it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv7Uwx6IwUGo",
        "outputId": "82a0fcba-0384-4529-b1b4-9e04d601ed5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# I uploaded the data to google drive as a zip file in order use it here\n",
        "# Mounting the drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heaEJiCUxdup"
      },
      "source": [
        "# unzipping the file, to be run only once\n",
        "!unzip '/content/drive/My Drive/Information systems/Assignment 1/orl_dataset.zip' -d '/content/drive/My Drive/Information systems/Assignment 1/Data set'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1av0tG2l4Bdh"
      },
      "source": [
        "## Reading the data to generate the data matrix and the label vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkkTLblD3_ot"
      },
      "source": [
        "def generate_data():\n",
        "  # first obtaining the directories and sorting them\n",
        "  subjects_dir = os.listdir(path_data);\n",
        "  # Note that I manually removed the readme file from my drive after unzipping the data\n",
        "  # sorting the directories to obtain the subjects' data sorted from 1 to 40\n",
        "  subjects_dir.sort(key = numeric_key_folders);\n",
        "  # converting the images to the flattened format and filling the D and Y matrices as required\n",
        "  D = [];\n",
        "  Y = [];\n",
        "  flatten_dim = image_len * image_width;\n",
        "  for current_dir in subjects_dir:\n",
        "    current_label = numeric_key_folders(current_dir);\n",
        "    subject_images = os.listdir(path_data + delim + current_dir);\n",
        "    # sorting the images to obtain the current subject's images sorted from 1 to 10\n",
        "    subject_images.sort(key = numeric_key_images);\n",
        "    for current_image in subject_images:\n",
        "      # image is reshaped to be flattened as a vector\n",
        "      D.append(mpimg.imread(path_data + delim + current_dir + delim + current_image).reshape(flatten_dim));\n",
        "      Y.append(current_label);\n",
        "  return np.array(D), np.array(Y);"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CRaR7r6Beij"
      },
      "source": [
        "## splitting the data and labels to training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om8tcs_3Bm_r"
      },
      "source": [
        "# this function splits the data according to specified values to take which for training and which for testing.\n",
        "# to get odd rows for training and even rows for testing, make train_each = test_each = 1 and start = testing (as matrices and vectors are 0 indexed).\n",
        "def split_data(D,Y,train_each = 1,test_each = 1,start = testing):\n",
        "  # flag checks whether data is in training or testing\n",
        "  destination = start;\n",
        "  # counter checks how many samples were taken\n",
        "  taken = 0;\n",
        "  D_train = [];\n",
        "  Y_train = [];\n",
        "  D_test = [];\n",
        "  Y_test = [];\n",
        "  for i in range(0, Y.shape[0]):\n",
        "    taken = taken + 1;\n",
        "    if destination == training:\n",
        "      D_train.append(D[i,:]);\n",
        "      Y_train.append(Y[i]);\n",
        "      if taken == train_each:\n",
        "        destination = testing;\n",
        "        taken = 0;\n",
        "    else:\n",
        "      D_test.append(D[i,:]);\n",
        "      Y_test.append(Y[i]);\n",
        "      if destination == testing:\n",
        "        destination = training;\n",
        "        taken = 0;\n",
        "  return np.array(D_train),np.array(Y_train),np.array(D_test),np.array(Y_test);    \n",
        "        \n"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC6pOiUPC5PE"
      },
      "source": [
        "# script to test the functions\n",
        "D,Y = generate_data(); \n",
        "D_train,Y_train,D_test,Y_test = split_data(D,Y);"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jJSQuVtGPS2"
      },
      "source": [
        "### BADAWY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8umYewLGFpc"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "path = path_data\n",
        "files = os.listdir(path)\n",
        "files.sort(key = lambda x : int(x[1:]))\n",
        "D , y = [], []\n",
        "ok = 1\n",
        "for f in files:\n",
        "  curr_path = path + '/' + f\n",
        "  images = os.listdir(curr_path)\n",
        "  #images.sort(key = lambda x : int(x[:-4]))\n",
        "  images.sort(key= lambda x : int(x[0: (len(x) - 4)]))\n",
        "  for i in images:\n",
        "    my_path = curr_path + '/' + i\n",
        "    img = cv2.imread(my_path, cv2.IMREAD_GRAYSCALE).flatten()\n",
        "    D.append(img)\n",
        "    y.append(int(f[1:]))"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d5jmCNpGTI7"
      },
      "source": [
        "X_training_50 = np.array([D[i] for i in range(len(D)) if i&1]).astype(float)\n",
        "y_training_50 = np.array([y[i] for i in range(len(y)) if i&1]).astype(int)\n",
        "X_test_50 = np.array([D[i] for i in range(len(D)) if i % 2 == 0]).astype(float)\n",
        "y_test_50 = np.array([y[i] for i in range(len(y)) if i % 2 == 0]).astype(int)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJIM9vCHGWwP"
      },
      "source": [
        "X_training_50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRuQCprRGX1-"
      },
      "source": [
        "X_test_50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlvxAR2UGinc"
      },
      "source": [
        "y_training_50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bLgAby_Gnui"
      },
      "source": [
        "y_test_50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRvGyqi4Gonz"
      },
      "source": [
        "X_training_50.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c55Zbx33GvAu"
      },
      "source": [
        "X_test_50.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqLvHuz_Gw9Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
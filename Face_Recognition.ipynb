{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNar/rP5rEr1VDFDwg8Kbwp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sherifmost/face-recognition/blob/main/Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlMQSGkWuRhC"
      },
      "source": [
        "# **About the project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlWcBMiNuYn4"
      },
      "source": [
        "This is a project in the information systems and software course. Our objective is to perform face recognition on the ORL dataset and test its accuracy using PCA and LDA along with KNN classifiers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoWtEudgurgr"
      },
      "source": [
        "# **About the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii2iyB4Hutuu"
      },
      "source": [
        "We used the ORL data set for face recognition, which contains 40 different subjects with 10 images each. Each image is a 92x112 image in PGM (Portable Gray Map) format. Images are classified by being placed in different directories; where those in folder sx belong to subject number x(x between 1 and 40). An image for a certain subject is named Y.pmg where Y is the image number (between 1 and 10).\n",
        "Credits to: *AT&T Laboratories Cambridge* for providing the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HlnhRnDvc97"
      },
      "source": [
        "# **Needed library imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-5KLVtTvxz3"
      },
      "source": [
        "from google.colab import drive\n",
        "# used to manipulate the folders containing the images and read them out\n",
        "import os\n",
        "import matplotlib.image as mpimg \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5BOIf4Gvy1O"
      },
      "source": [
        "# **Labels and constants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9mMSXtkv5Q8"
      },
      "source": [
        "# file paths\n",
        "path_data = '/content/drive/My Drive/Information systems/Assignment 1/Data set';\n",
        "\n",
        "# symbols\n",
        "delim = '/';\n",
        "\n",
        "# image dimensions\n",
        "image_len = 92;\n",
        "image_width = 112;\n",
        "\n",
        "# constant numbers\n",
        "training = 1;\n",
        "testing = -1;\n",
        "num_subjects = 40;"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcphDZSL6gOh"
      },
      "source": [
        "# **Helper functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR3Onf9Lx411"
      },
      "source": [
        "## Helper functions for manipuating data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK0_u8y757BS"
      },
      "source": [
        "# functions used as keys for sort function\n",
        "def numeric_key_folders(x):\n",
        "  return int(x[1:]);\n",
        "def numeric_key_images(x):\n",
        "  # we want to get the number till .pmg so remove last 4 characters from the string considered\n",
        "  return int(x[0:(len(x)-4)]);"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29nbI6gIx_JJ"
      },
      "source": [
        "## Helper functions for LDA classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds4DF3hjps5r"
      },
      "source": [
        "# function calculates the class means (mean of each class) given an array containing the number of samples per class (assuming the data matrix is sorted accordingly)\n",
        "def get_class_means(D,num_samples):\n",
        "  means = [];\n",
        "  # keep the begining of the class from which the mean is calculated\n",
        "  class_begin = 0;\n",
        "  for curr_num in num_samples:\n",
        "    curr_num = int(curr_num);\n",
        "    means.append(np.mean(D[class_begin : class_begin + curr_num,:],axis = 0));\n",
        "    class_begin = class_begin + curr_num;\n",
        "  return np.array(means);\n",
        "# function that calculates the S_b matrix given the number of samples for each class, the class means and the overall mean\n",
        "def get_S_b(num_samples,class_means):\n",
        "  # calculating the overal sample mean\n",
        "  overal_mean = np.mean(class_means,axis = 0);\n",
        "  # S_b has dimensions same as B which are d x d (where d is number of dimensions which is same as shape of the image after flattening)\n",
        "  S_b = np.zeros(shape = (overal_mean.shape[0],overal_mean.shape[0]));\n",
        "  # looping to calculate S_b\n",
        "  for i in range(0,num_samples.shape[0]):\n",
        "    S_b = S_b + num_samples[i] * np.dot((class_means[i,:] - overal_mean).reshape(overal_mean.shape[0],1),(class_means[i,:] - overal_mean).reshape(1,overal_mean.shape[0]));\n",
        "  return S_b;\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctPEnjwTv6Fh"
      },
      "source": [
        "# **Obtaining the data and cleaning it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv7Uwx6IwUGo",
        "outputId": "5202fc4f-c41e-4181-c115-d37c4a9a7e00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# I uploaded the data to google drive as a zip file in order use it here\n",
        "# Mounting the drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heaEJiCUxdup"
      },
      "source": [
        "# unzipping the file, to be run only once\n",
        "!unzip '/content/drive/My Drive/Information systems/Assignment 1/orl_dataset.zip' -d '/content/drive/My Drive/Information systems/Assignment 1/Data set'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1av0tG2l4Bdh"
      },
      "source": [
        "## Reading the data to generate the data matrix and the label vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkkTLblD3_ot"
      },
      "source": [
        "def generate_data():\n",
        "  # first obtaining the directories and sorting them\n",
        "  subjects_dir = os.listdir(path_data);\n",
        "  # Note that I manually removed the readme file from my drive after unzipping the data\n",
        "  # sorting the directories to obtain the subjects' data sorted from 1 to 40\n",
        "  subjects_dir.sort(key = numeric_key_folders);\n",
        "  # converting the images to the flattened format and filling the D and Y matrices as required\n",
        "  D = [];\n",
        "  Y = [];\n",
        "  flatten_dim = image_len * image_width;\n",
        "  for current_dir in subjects_dir:\n",
        "    current_label = numeric_key_folders(current_dir);\n",
        "    subject_images = os.listdir(path_data + delim + current_dir);\n",
        "    # sorting the images to obtain the current subject's images sorted from 1 to 10\n",
        "    subject_images.sort(key = numeric_key_images);\n",
        "    for current_image in subject_images:\n",
        "      # image is reshaped to be flattened as a vector\n",
        "      D.append(mpimg.imread(path_data + delim + current_dir + delim + current_image).reshape(flatten_dim));\n",
        "      Y.append(current_label);\n",
        "  return np.array(D), np.array(Y);"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CRaR7r6Beij"
      },
      "source": [
        "## splitting the data and labels to training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om8tcs_3Bm_r"
      },
      "source": [
        "# this function splits the data according to specified values to take which for training and which for testing.\n",
        "# to get odd rows for training and even rows for testing, make train_each = test_each = 1 and start = testing (as matrices and vectors are 0 indexed).\n",
        "def split_data(D,Y,train_each = 1,test_each = 1,start = testing):\n",
        "  # flag checks whether data is in training or testing\n",
        "  destination = start;\n",
        "  # counter checks how many samples were taken\n",
        "  taken = 0;\n",
        "  D_train = [];\n",
        "  Y_train = [];\n",
        "  num_samples_train = np.array(np.zeros(num_subjects));\n",
        "  D_test = [];\n",
        "  Y_test = [];\n",
        "  num_samples_test = np.array(np.zeros(num_subjects));\n",
        "  for i in range(0, Y.shape[0]):\n",
        "    taken = taken + 1;\n",
        "    if destination == training:\n",
        "      D_train.append(D[i,:]);\n",
        "      Y_train.append(Y[i]);\n",
        "      num_samples_train[Y[i] - 1] = num_samples_train[Y[i] - 1] + 1; \n",
        "      if taken == train_each:\n",
        "        destination = testing;\n",
        "        taken = 0;\n",
        "    else:\n",
        "      D_test.append(D[i,:]);\n",
        "      Y_test.append(Y[i]);\n",
        "      num_samples_test[Y[i] - 1] = num_samples_test[Y[i] - 1] + 1; \n",
        "      if destination == testing:\n",
        "        destination = training;\n",
        "        taken = 0;\n",
        "  return np.array(D_train),np.array(Y_train),num_samples_train,np.array(D_test),np.array(Y_test),num_samples_test;    \n",
        "        \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N4ccEw8oZCD"
      },
      "source": [
        "# **Classification using LDA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYEmq3Jew34Q"
      },
      "source": [
        "def classify_lda(D_train,Y_train,num_samples_train):\n",
        "  # getting the class means for the training data\n",
        "  means_class = get_class_means(D_train,num_samples_train);\n",
        "  # getting S_b (which replaces the between-class scatter matrix B in case of multiclass LDA)\n",
        "  S_b_train = get_S_b(num_samples_train,means_class); \n",
        "  \n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4G0ZQd9n7N0"
      },
      "source": [
        "# **Scripts used to run the function and give the required outputs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC6pOiUPC5PE"
      },
      "source": [
        "# script to generate the data and split it\n",
        "D,Y = generate_data(); \n",
        "D_train,Y_train,n_train,D_test,Y_test,n_test = split_data(D,Y);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vio3IJMcuZQ8"
      },
      "source": [
        "# script to perform the LDA classification\n",
        "means_train = get_class_means(D_train,n_train);"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6csXFPNg46_Z"
      },
      "source": [
        "means_overal = np.mean(means_train,axis = 0);"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-k0p3Qj5Ejm",
        "outputId": "38368835-03a4-4b59-89c1-70ea58fe5ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.dot((means_train[0,:] - means_overal),(means_train[0,:] - means_overal).T)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14631603.09015])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkr72VCQ5juF",
        "outputId": "6e7ce54d-748b-491c-a4bc-39e371170fd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(means_train[0,:] - means_overal).reshape(1,(means_train[0,:] - means_overal).shape[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-36.32 , -36.89 , -44.565, ..., -15.04 , -18.335, -13.97 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jh2RWd87zZ62",
        "outputId": "bd9dcae5-b1df-42dd-f5a5-9818799c657a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "S_b = get_S_b(n_train,means_train)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7IUPxvo2Npa",
        "outputId": "e8ee2067-7aaa-470e-e443-de7b6326e57a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "S_b.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10304, 10304)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}